## 用于开放式词汇目标检测的内置检测器中区域词对齐的探索

开放式词汇目标检测旨在检测独立于训练过程中使用的基本类别的新类别。大多数现代方法都坚持从大规模多模态语料库中学习视觉语言空间，然后将所获得的知识转移到现成的检测器，如 Faster RCNN。然而，在知识转移过程中，由于领域差距阻碍了对新类别的泛化能力，信息可能会衰减或破坏。为了缓解这一困境，我们在本文中提出了一个新的框架，名为 BIND，代表 Bulit in 检测器，以消除对模块更换或知识转移到现成检测器的需求。

## SHiNee：开放词汇对象检测的语义层次结构 Nexus

开放词汇目标检测(OVOD)将检测转变为一种语言主导的任务，允许用户在推理过程中自由定义他们感兴趣的类别。然而，我们的初步调查表明，现有的Ovod 检测器在处理跨不同语义粒度的词汇时表现出显着的可变性，这给现实世界的部署带来了担忧。为此，我们引入了语义层次 Nexus(SISH)，这是一种使用来自类别层次的语义知识的新型分类器。

## 生成增强的负值以训练基于数据的目标检测器

用辨别性目标函数训练这种模型已被证明是成功的，但需要良好的正样本和负样本。然而，自由形式的性质和目标描述的开放词汇使得负样本空间非常大。以前的工作是随机抽样底片或使用基于规则的技术来构建底片。相反，我们建议利用现代生成模型中内置的大量知识来自动构建与原始数据更相关的负样本。

## DetCLIPv3：迈向多功能生成开放词汇目标检测

现有的开放词汇目标检测器通常需要用户提供一组预定义的类别，这大大限制了他们的应用场景。在本文中，我们介绍了一种高性能的检测器，它不仅擅长于开放词汇的目标检测，而且还擅长为被检测的目标生成分层标签。

## 探索开放世界目标检测中的正交性
开放世界目标检测的目标是识别不可见类别的物体，并在提供其注释后逐步识别它们。与仅限于预定义类别的传统范式不同，这种设置承诺了一种使用类不可知信息来估计客观性的连续且可概括的方法。然而，实现客观性和类别信息之间的这种去相关性被证明是具有挑战性的。在没有明确考虑的情况下，现有的方法通常对未知对象的召回率较低，并且会将它们错误地分类到已知的类中。为了解决这个问题，我们在检测过程中利用了三个级别的正交性。

## 温度调节 Detection Transformer

提出了一种新的开放词汇检测框架。我们的框架使用图像级标签和详细的检测注释(如果可用)。我们的框架分三个步骤进行。

## 魔鬼就在细粒度细节中：评估开放词汇目标检测器以实现细粒度理解&#x20;

大型视觉语言模型的最新进展使开放词汇场景中的视觉目标检测成为可能，其中目标类别在推理过程中以自由文本格式定义。在本文中，我们旨在探索开放词汇目标检测的最新方法，以确定他们在多大程度上理解目标及其部分的细粒度属性。为此，我们引入了一种基于动态词汇表生成的评估协议来测试在存在硬负类的情况下，模型是否能够检测、识别并为目标分配正确的细粒度描述。&#x20;

## 学习背景致力于发现开放词汇目标检测的隐性知识

开放词汇目标检测(OVD)旨在寻找一种既能识别基本类别对象又能识别新类别对象的最优目标检测器。最近的进展利用知识蒸馏将有洞察力的知识从预先训练的大规模视觉语言模型转移到目标检测任务中，显着地推广了检测器识别更多未知对象类别的强大能力。然而，这些方法在背景解释和模型过拟合方面面临着巨大的挑战，从而经常导致关键背景知识的丢失，从而导致检测器的推理性能次优。为了缓解这些问题，我们提出了一种新的 OVD 框架，称为 LBP，它提出了学习背景提示来利用已探索的隐含背景知识，从而提高了检测性能。&#x20;

## 用于开放词汇对象检测的场景自适应和区域感知的多模态提示&#x20;

开放词汇对象检测(OVD)的目的是基于训练类的泛化能力，从文本输入描述的新类别中检测对象。现有的方法主要集中在通过知识提炼将知识从大视觉和语言模型(VLM)转移到检测器。然而，这些方法对不同类别的适应能力较弱，图像级别的预训练和区域级别的检测之间的对准能力较弱，从而阻碍了有效的知识传递。在提示调整的启发下，我们提出了场景自适应和区域感知的多模态提示，通过将 VLM中的类感知知识有效地适应到区域级的检测器来解决这些问题。&#x20;

## YOLO-World：实时开放词汇对象检测&#x20;

你只看一次(YOLO)系列探测器已经成为高效和实用的工具。然而，它们对预定义和训练的对象类别的依赖限制了它们在开放场景中的适用性。针对这一局限性，我们引入了 YOLO-World，这是一种创新的方法，通过在大规模数据集上进行视觉语言建模和预训练，增强了 YOLO 的开放词汇检测能力。&#x20;

## 开放词汇对象检测的自训练&#x20;

最近的研究表明，通过利用来自预先训练的视觉和语言模型(VLM)的伪标签(PL)，在开放词汇对象检测(OVD)中具有良好的性能。然而，教师-学生自训练这一强大且被广泛使用的范例很少在 OVD 中被探索。这项工作确定了在 OVD 中使用自训练的两个挑战：来自 VLMS 的噪声 PLS 和频繁的 PLS 分布变化。为了应对这些挑战，我们提出了 SAS-DET，从两个关键角度实现 OVD 的自训练。&#x20;

## 检索增强的开放词汇对象检测&#x20;

利用视觉语言模型(VLMS)对开放词汇对象检测(OVD)进行了研究，以检测超出预先训练类别的新对象。以前的方法改进了泛化能力，使用带有额外的类名称的正的伪标签来扩展检测器的知识，例如 sock、 iPod 和 alligator 。为了从两个方面对以前的方法进行扩展，我们提出了检索增强损失和视觉特征(RAIF)。&#x20;

# [CVPR 2024论文合集PDF版](https://mbd.pub/o/bread/ZpeYmplt)
由于判断依据的差异，这篇博客可能无法全面地囊括您需要的论文。

下面的资料中收录并翻译了CVPR 2024所有论文的题目与摘要，它为您扫清了语言障碍，让您能够充分地利用碎片时间、随时随地跟踪计算机视觉与模式识别领域最前沿的研究。
CVPR 2024 收录所有论文题目和题目的合集：[https://mbd.pub/o/bread/ZpeYmplt](https://mbd.pub/o/bread/ZpeYmplt)
CVPR 2024 收录所有论文题目的合集：[https://mbd.pub/o/bread/ZpeYmphy](https://mbd.pub/o/bread/ZpeYmphy)
