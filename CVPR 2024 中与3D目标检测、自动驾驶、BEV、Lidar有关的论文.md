
## UniMODE：统一的单目 3D 目标检测

实现包括室内和室外场景的统一单目 3D 目标检测在机器人导航等应用中具有重要意义。然而，涉及数据的各种场景来训练模型会带来挑战，因为它们具有显著不同的特性，例如不同的几何特性和异构的域分布。为了解决这些挑战，我们构建了一种基于鸟瞰图（BEV）检测范式的检测器。
## LaneCPP：使用物理优先级的连续 3D 车道检测

单目 3D 车道检测已成为自动驾驶领域的一个基本问题，自动驾驶包括寻找路面和定位车道标线的任务。

## MonoDiff：使用扩散模型的单目 3D 对象检测和姿势估计

由于缺乏 3D 感知带来的高度不确定性，从单视图像中进行 3D 目标检测和姿态估计是具有挑战性的。作为一种解决方案，最近的单目 3D 检测方法利用诸如立体图像对和 LiDAR 点云等额外的模式来增强图像特征，但代价是额外的注释成本。我们建议使用扩散模型来学习单目 3D 检测的有效表示，而不需要额外的模式或训练数据。我们提出了一个新的框架 MonoDiff，它使用反向扩散过程来估计 3D 边界框和方向。

## 跨数据集 3D 目标检测的无监督域自适应伪标签精炼

最近的自训练技术在用于 3D 对象检测的无监督域自适应(3D UDA)方面显示出显著的改进。这些技术通常选择伪标签，即 3D 框来监督目标域的模型。然而，这种选择过程不可避免地引入了不可靠的 3D 框，其中 3D 点不能被确定地分配为前景或背景。以前的技术通过将这些框重新加权为伪标签来缓解这一问题，但这些框仍然会干扰训练过程。为了解决这一问题，本文提出了一种新的伪标签精炼框架。

## VSRD：用于弱监督3D目标检测的实例感知体积轮廓绘制

单目 3D 对象检测由于其在单目深度估计中固有的不适定性，在 3D 场景理解中构成了重大挑战。现有的方法在很大程度上依赖于使用丰富的 3D 标签的监督学习，这些标签通常是通过在激光雷达点云上进行昂贵且劳动密集的注释来获得的。为了解决这个问题，我们提出了一种新的弱监督 3D 目标检测框架，称为 VSRD（检测的体积轮廓绘制），用于训练没有任何 3D 监督但只有弱 2D 监督的 3D 目标检测器。

## 海鸟：具有骰子丢失的鸟瞰图分割改进了大型物体的单目 3D 检测

单目 3D 检测器在汽车和较小物体上实现了卓越的性能。然而，它们在较大物体上的性能下降会导致致命的事故。一些研究者将这种失败归因于训练数据稀缺或大型物体对感受野的要求。在这篇文章中，我们强调了现有检测器对大目标的泛化问题。我们发现，即使在几乎平衡的数据集上，现有的检测器也很难推广到大型物体。我们认为，失败的原因是深度回归损失对较大物体噪声的敏感性。

## HUNTER：通过将知识从合成实例转移到真实场景，实现无人监督的以人为中心的 3D 检测

以人为中心的 3D 场景理解最近因其对机器人的关键影响而引起越来越多的关注。然而，以人为中心的现实生活场景极其多样和复杂，人类有着复杂的动作和互动。由于标记数据有限，监督方法很难推广到阻碍实际应用的一般场景。模仿人类智能，我们通过将知识从合成的人类实例转移到真实场景、设计了一种无监督的 3D 检测方法，用于以人为中心的场景。

## 用于半监督单目3D目标检测的解耦伪标记

我们深入研究了半监督单目 3D 对象检测（SSM3OD）的伪标记，并发现了两个主要问题：3D 和 2D 属性的预测质量之间的偏差，以及伪标记产生的深度监督的噪声趋势，导致与其他可靠监督形式的显着优化冲突。为了解决这些问题，我们为 SSM3OD 引入了一种新的解耦伪标记（DPL）方法。

## 使用单视图图像的弱监督单目 3D 检测

单目 3D 检测(M3D)的目的是从单视图像中精确定位 3D 目标，这通常需要对3D 检测框进行费力的标注。弱监督 M3D 最近被研究，它们通过利用现有的许多 2D 标注来避免 3D 标注过程，但它通常需要额外的训练数据，如 LiDAR 点云或多视角图像，这大大降低了其在各种应用中的适用性和可用性。我们提出了 SKD-WM3D，这是一个弱监督的单目 3D 检测框架，它利用深度信息来实现只包含单视图的M3D，而不需要任何 3D 注释或其他训练数据。

## RCBEVDet：鸟瞰视图中雷达-相机融合用于 3D 目标检测

3D 目标检测是自动驾驶的关键任务之一。为了在实际应用中降低成本，人们提出了用低成本的多视角摄像机来代替扩展的 LiDAR 传感器。然而，仅仅依靠摄像机很难实现高精度、高鲁棒性的 3D 目标检测。解决这一问题的一个有效方案是将多视角摄像机与经济型毫米波雷达传感器相结合，实现更可靠的多模态 3D 目标检测。本文介绍了一种雷达与摄像机融合的鸟瞰三维目标检测方法 RCBEVDet。

## A-Teacher：用于 3D 半监督目标检测的非对称网络

提出了第一个在线非对称半监督框架 A-Teacher，用于基于 LiDAR 的 3D 目标检测。我们的动机源于这样的观察：1)现有的对称师生方法具有简单的特点，但由于需要相同的模型结构和输入数据格式，阻碍了教师和学生之间的蒸馏性能。2)不同构造复杂教师模型的离线非对称方法可以生成更精确的伪标签，但对教师和学生模型的联合优化具有挑战性。因此，在本文中，我们设计了一条不同于传统范式的路径，它可以利用一名强大的教师的能力，同时保留在线教师模型更新的优势。

## MonoCD：具有互补深度的单目 3D 对象检测

单目3D目标检测由于其能够以较低的成本从单幅图像中准确地获得目标3D位置而引起了广泛的关注。由于 2D 到 3D 映射的不适定性，深度估计是单目 3D目标检测的一个重要但具有挑战性的子任务。许多方法利用物体高度和关键点等多个局部深度信息，然后将物体深度估计表示为多个深度预测的集合，以缓解单一深度信息的不足。然而，现有多个深度的误差往往具有相同的符号，这阻碍了它们之间的相互抵消，并限制了组合深度的整体精度。为了缓解这一问题，我们建议通过两种新颖的设计来增加深度的互补性。

## BEVSpread：在基于视觉的路边 3D 目标检测中进行鸟瞰图表示的扩展体素池

基于视觉的路边3D目标检测由于其在减少盲区、扩大感知范围等方面的固有优势，在自动驾驶领域受到越来越多的关注。而以往的工作主要集中在 2D 到 3D 映射的深度或高度的精确估计上，而忽略了体素池化过程中的位置逼近误差。受此启发，我们提出了一种新颖的体素合并策略来减少这种误差，称为 BEVSspend。

## 用于多视图 3D 目标检测的多视图专注上下文化

在基于查询的多视图 3D(MV3D)目标检测中，提出了一种简单而有效的改进 2D 到 3D 特征提升的方法--多视图注意力上下文(MvACon)。尽管在基于查询的 MV3D 对象检测领域见证了显着的进步，但现有技术由于计算成本高而在密集的基于注意力的提升中缺乏利用高分辨率 2D 特征，或者在稀疏的基于注意力的提升中缺乏对 3D 查询的不够密集的基础到多尺度 2D 特征。我们提出的 MvACon 使用了一种具有代表性的密集但计算稀疏的关注特征上下文化方案一石二鸟，该方案与特定的 2D 到 3D 特征提升方法无关。

## GAFusion：自适应融合 LiDART 和具有多重引导的摄像机用于 3D 目标检测&#x20;

近年来，基于鸟眼视角的 3D 多模态目标检测方法取得了长足的进步。然而，它们大多忽略了激光雷达与相机之间的相互交互和引导。在本文中，我们提出了一种基于激光雷达引导的全局交互和自适应融合的多通道 3D 目标检测方法GAFusion。&#x20;

## 在各种天气条件下通过 LiDART 和 4D 雷达融合实现稳健的 3D 目标检测&#x20;

在各种(正常和恶劣)天气条件下以 3D 方式检测目标对于安全的自动驾驶系统至关重要。最近的方法侧重于使用天气不敏感的 4D 雷达传感器，并将其与激光雷达等其他模式相结合。本文提出了一种新的基于激光雷达和四维雷达的3D目标检测框架。&#x20;

## 使用 2D 边界框监督改进对远距离 3D 目标的检测&#x20;

提高对远距离 3D 物体的检测是一项重要而又具有挑战性的任务。对于基于相机的 3D 感知， 3D 边界的标注在很大程度上依赖于 LiDAR 来获得准确的深度信息。因此，由于远距离物体上 LiDAR 点的稀疏性，注记的距离往往是有限的，这阻碍了现有检测器对远程场景的能力。我们通过只考虑对远距离目标的 2D 边界框监督来解决这一挑战，因为它们很容易标注。我们提出了一种 LR3D 框架，该框架能够学习恢复远距离目标丢失的深度。&#x20;

## 激光雷达 3D 目标检测器对不可见区域的概括能力的实证研究&#x20;

在许多机器人任务中，3D 目标检测器(3D-OD)对于理解环境是至关重要的，特别是在自动驾驶中。通过激光雷达传感器包含 3D 信息大大提高了精度。然而，这类探测器在没有经过培训的领域表现不佳，即不同的位置、传感器、天气等，限制了它们在安全关键应用中的可靠性。有一些方法可以使 3D-OD 适应于这些领域；然而，这些方法将 3D-OD 视为一个黑匣子，忽略了潜在的体系结构决策和源域训练策略。相反，我们深入研究 3D-OD 的细节，重点放在影响域适应之前的健壮性的基本因素上。

## 利用 X 射线蒸馏进行弱到强的 3D 物体检测&#x20;

本文研究了基于 LiDAR 的 3D 目标检测中稀疏性和遮挡的关键问题。当前的方法通常依赖于补充模块或特定的体系结构设计，潜在地限制了它们对新的和不断发展的体系结构的适用性。据我们所知，我们是第一个提出一种通用的技术，它可以无缝地集成到任何现有的 3D 目标检测框架中，标志着 3D 计算机视觉中第一个从弱到强的泛化。我们介绍了一种新的框架 X 射线蒸馏与对象完整的框架，既适用于监督和半监督设置，利用点云序列的时间方面。&#x20;

## SAFDNet：一种简单有效的全稀疏 3D 对象检测网络

基于激光雷达的3D目标检测在自动驾驶中起着至关重要的作用。现有的高性能 3D 目标检测器通常在主干网络和预测头部构建密集的特征地图。然而，密集特征映射引入的计算成本随着感知范围的增加而呈二次曲线增长，使得这些模型很难扩展到远程检测。最近的一些工作试图构造完全稀疏的检测器来解决这个问题，然而得到的模型要么依赖于复杂的多级管道，要么表现出较差的性能。在这项工作中，我们提出了一种完全稀疏的自适应特征扩散网络(SAFDNet)用于基于 LiDAR 的3D目标检测。&#x20;

# [CVPR 2024论文合集PDF版](https://mbd.pub/o/bread/ZpeYmplt)

由于判断依据的差异，这篇博客可能无法全面地囊括您需要的论文。

下面的资料中收录并翻译了CVPR 2024所有论文的题目与摘要，它为您扫清了语言障碍，让您能够充分地利用碎片时间、随时随地跟踪计算机视觉与模式识别领域最前沿的研究。
CVPR 2024 收录所有论文题目和题目的合集：<https://mbd.pub/o/bread/ZpeYmplt>
CVPR 2024 收录所有论文题目的合集：<https://mbd.pub/o/bread/ZpeYmphy>
