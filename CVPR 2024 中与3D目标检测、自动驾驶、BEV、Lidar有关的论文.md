# 3D 目标检测
## UniMODE：统一的单目 3D 对象检测
实现包括室内和室外场景的统一单目 3D 对象检测在机器人导航等应用中具有重要意义。然而，涉及数据的各种场景来训练模型会带来挑战，因为它们具有显著不同的特性，例如不同的几何特性和异构的域分布。为了解决这些挑战，我们构建了一种基于鸟瞰图（BEV）检测范式的检测器。
## LaneCPP：使用物理优先级的连续 3D 车道检测
单目 3D 车道检测已成为自动驾驶领域的一个基本问题，自动驾驶包括寻找路面和定位车道标线的任务。
## MonoDiff：使用扩散模型的单目 3D 对象检测和姿势估计
由于缺乏 3D 感知带来的高度不确定性，从单视图像中进行 3D 目标检测和姿态估计是具有挑战性的。作为一种解决方案，最近的单目 3D 检测方法利用诸如立体图像对和 LiDAR 点云等额外的模式来增强图像特征，但代价是额外的注释成本。我们建议使用扩散模型来学习单目 3D 检测的有效表示，而不需要额外的模式或训练数据。我们提出了一个新的框架 MonoDiff，它使用反向扩散过程来估计 3D 边界框和方向。
## 跨数据集 3D 目标检测的无监督域自适应伪标签精炼
最近的自训练技术在用于 3D 对象检测的无监督域自适应(3D UDA)方面显示出显著的改进。这些技术通常选择伪标签，即 3D 框来监督目标域的模型。然而，这种选择过程不可避免地引入了不可靠的 3D 框，其中 3D 点不能被确定地分配为前景或背景。以前的技术通过将这些框重新加权为伪标签来缓解这一问题，但这些框仍然会干扰训练过程。为了解决这一问题，本文提出了一种新的伪标签精炼框架。
## VSRD：用于弱监督3D目标检测的实例感知体积轮廓绘制
单目 3D 对象检测由于其在单目深度估计中固有的不适定性，在 3D 场景理解中构成了重大挑战。现有的方法在很大程度上依赖于使用丰富的 3D 标签的监督学习，这些标签通常是通过在激光雷达点云上进行昂贵且劳动密集的注释来获得的。为了解决这个问题，我们提出了一种新的弱监督 3D 目标检测框架，称为 VSRD（检测的体积轮廓绘制），用于训练没有任何 3D 监督但只有弱 2D 监督的 3D 目标检测器。
## 海鸟：具有骰子丢失的鸟瞰图分割改进了大型物体的单目 3D 检测
单目 3D 检测器在汽车和较小物体上实现了卓越的性能。然而，它们在较大物体上的性能下降会导致致命的事故。一些研究者将这种失败归因于训练数据稀缺或大型物体对感受野的要求。在这篇文章中，我们强调了现有检测器对大目标的泛化问题。我们发现，即使在几乎平衡的数据集上，现有的检测器也很难推广到大型物体。我们认为，失败的原因是深度回归损失对较大物体噪声的敏感性。
## HUNTER：通过将知识从合成实例转移到真实场景，实现无人监督的以人为中心的 3D 检测
以人为中心的 3D 场景理解最近因其对机器人的关键影响而引起越来越多的关注。然而，以人为中心的现实生活场景极其多样和复杂，人类有着复杂的动作和互动。由于标记数据有限，监督方法很难推广到阻碍实际应用的一般场景。模仿人类智能，我们通过将知识从合成的人类实例转移到真实场景、设计了一种无监督的 3D 检测方法，用于以人为中心的场景。
## 用于半监督单目3D目标检测的解耦伪标记
我们深入研究了半监督单目 3D 对象检测（SSM3OD）的伪标记，并发现了两个主要问题：3D 和 2D 属性的预测质量之间的偏差，以及伪标记产生的深度监督的噪声趋势，导致与其他可靠监督形式的显着优化冲突。为了解决这些问题，我们为 SSM3OD 引入了一种新的解耦伪标记（DPL）方法。

## 使用单视图图像的弱监督单目 3D 检测
单目 3D 检测(M3D)的目的是从单视图像中精确定位 3D 目标，这通常需要对3D 检测框进行费力的标注。弱监督 M3D 最近被研究，它们通过利用现有的许多 2D 标注来避免 3D 标注过程，但它通常需要额外的训练数据，如 LiDAR 点云或多视角图像，这大大降低了其在各种应用中的适用性和可用性。我们提出了 SKD-WM3D，这是一个弱监督的单目 3D 检测框架，它利用深度信息来实现只包含单视图的M3D，而不需要任何 3D 注释或其他训练数据。

## RCBEVDet：鸟瞰视图中雷达-相机融合用于 3D 目标检测
3D 目标检测是自动驾驶的关键任务之一。为了在实际应用中降低成本，人们提出了用低成本的多视角摄像机来代替扩展的 LiDAR 传感器。然而，仅仅依靠摄像机很难实现高精度、高鲁棒性的 3D 目标检测。解决这一问题的一个有效方案是将多视角摄像机与经济型毫米波雷达传感器相结合，实现更可靠的多模态 3D 目标检测。本文介绍了一种雷达与摄像机融合的鸟瞰三维目标检测方法 RCBEVDet。
## A-Teacher：用于 3D 半监督目标检测的非对称网络
提出了第一个在线非对称半监督框架 A-Teacher，用于基于 LiDAR 的 3D 目标检测。我们的动机源于这样的观察：1)现有的对称师生方法具有简单的特点，但由于需要相同的模型结构和输入数据格式，阻碍了教师和学生之间的蒸馏性能。2)不同构造复杂教师模型的离线非对称方法可以生成更精确的伪标签，但对教师和学生模型的联合优化具有挑战性。因此，在本文中，我们设计了一条不同于传统范式的路径，它可以利用一名强大的教师的能力，同时保留在线教师模型更新的优势。
## MonoCD：具有互补深度的单目 3D 对象检测
单目3D目标检测由于其能够以较低的成本从单幅图像中准确地获得目标3D位置而引起了广泛的关注。由于 2D 到 3D 映射的不适定性，深度估计是单目 3D目标检测的一个重要但具有挑战性的子任务。许多方法利用物体高度和关键点等多个局部深度信息，然后将物体深度估计表示为多个深度预测的集合，以缓解单一深度信息的不足。然而，现有多个深度的误差往往具有相同的符号，这阻碍了它们之间的相互抵消，并限制了组合深度的整体精度。为了缓解这一问题，我们建议通过两种新颖的设计来增加深度的互补性。
## BEVSpread：在基于视觉的路边 3D 目标检测中进行鸟瞰图表示的扩展体素池
基于视觉的路边3D目标检测由于其在减少盲区、扩大感知范围等方面的固有优势，在自动驾驶领域受到越来越多的关注。而以往的工作主要集中在 2D 到 3D 映射的深度或高度的精确估计上，而忽略了体素池化过程中的位置逼近误差。受此启发，我们提出了一种新颖的体素合并策略来减少这种误差，称为 BEVSspend。
## 用于多视图 3D 目标检测的多视图专注上下文化
在基于查询的多视图 3D(MV3D)目标检测中，提出了一种简单而有效的改进 2D 到 3D 特征提升的方法--多视图注意力上下文(MvACon)。尽管在基于查询的 MV3D 对象检测领域见证了显着的进步，但现有技术由于计算成本高而在密集的基于注意力的提升中缺乏利用高分辨率 2D 特征，或者在稀疏的基于注意力的提升中缺乏对 3D 查询的不够密集的基础到多尺度 2D 特征。我们提出的 MvACon 使用了一种具有代表性的密集但计算稀疏的关注特征上下文化方案一石二鸟，该方案与特定的 2D 到 3D 特征提升方法无关。

# [CVPR 2024论文合集PDF版](https://mbd.pub/o/bread/ZpeYmplt)
由于判断依据的差异，这篇博客可能无法全面地囊括您需要的论文。

下面的资料中收录并翻译了CVPR 2024所有论文的题目与摘要，它为您扫清了语言障碍，让您能够充分地利用碎片时间、随时随地跟踪计算机视觉与模式识别领域最前沿的研究。
CVPR 2024 收录所有论文题目和题目的合集：[https://mbd.pub/o/bread/ZpeYmplt](https://mbd.pub/o/bread/ZpeYmplt)
CVPR 2024 收录所有论文题目的合集：[https://mbd.pub/o/bread/ZpeYmphy](https://mbd.pub/o/bread/ZpeYmphy)

# 小样本目标检测
## 基于基础模型的小样本目标检测.
小样本目标检测（FSOD）旨在检测只有几个训练例子的目标。视觉特征提取和查询支持相似性学习是两个关键组成部分。现有的工作通常是基于 ImageNet 预训练的视觉骨干进行开发的，并为小样本学习设计复杂的度量学习网络，但精度仍然较差。在这项工作中，我们研究了使用现代基础模型的小样本目标检测。

# 分布外检测
## 测试时间线性分布外检测
分布外（OOD）检测旨在通过在输入样本显著偏离训练分布（分布中）时触发警报来解决神经网络的过度置信度预测，这表明输出可能不可靠。
## CORES：基于卷积响应的分布外检测分数
深度神经网络（DNN）在遇到分布外（OOD）样本时往往表现出过度自信，这在现实世界的应用中带来了重大挑战。

## 房间里的一只吵闹的大象：您的分布外检测器对标记噪音是否稳健？
检测不熟悉或意外图像的能力对于计算机视觉系统的安全部署至关重要。在分类的背景下，检测模型训练域之外的图像的任务称为分布外(OOD)检测。虽然人们对开发后自组织 OOD 检测方法的研究兴趣越来越大，但对于这些方法在底层分类器没有在干净、精心挑选的数据集上进行训练时如何执行的讨论相对较少。在这项工作中，我们在(更现实的)场景中更仔细地研究了 20 种最先进的 OOD 检测方法，其中用于训练底层分类器的标签是不可靠的(例如，众包标签或网络抓取的标签)。
## 用于小样本分布外检测的类似 ID 的提示学习
分布外(OOD)检测方法通常利用辅助离群点来训练识别 OOD 样本的模型，特别是从辅助离群点数据集中发现具有挑战性的离群点来改进 OOD 检测。然而，在有效区分与分布内(ID)数据非常相似的最具挑战性的 OOD 样本(即类似 ID 的样本)方面，它们可能仍然面临限制。为此，我们提出了一种新颖的 OOD 检测框架，该框架利用 ID 样本的邻近空间中的 CLIP 来发现类似 ID 的离群点，从而帮助识别这
些最具挑战性的 OOD 样本。
## YolOOD：利用目标检测概念进行多标签分发外检测
由于分布外(OOD)检测在已部署系统中的重要性，近年来引起了机器学习研究界的广泛关注。以往的研究大多集中在多类分类任务中 OOD 样本的检测。然而，在多标签分类任务中的 OOD 检测，一个更常见的真实世界用例，仍然是一个未被探索的领域。在本研究中，我们提出了一种利用目标检测领域的概念来进行多标签分类任务中的 OOD 检测的方法 YolOOD。

## 用于分布外检测的辨别性驱动通道选择
分布外(OOD)检测对于在开放世界环境中部署机器学习模型至关重要。基于激活的方法是 OOD 检测中的关键方法，致力于减轻对 OOD 数据的过度自信预测。这些技术纠正了异常激活，提高了分布内(ID)数据和 OOD 数据之间的可区分性。然而，它们默认假设每个通道都是 OOD 检测和纠正每个通道中的异常激活所必需的。经验证据表明，不同的信道在 OOD 检测中存在着显着的差异，丢弃部分通道可以大大提高 OOD 检测的性能。

## 改进单域广义目标检测：关注多元化和对齐
在这项工作中，我们解决了用于目标检测的域泛化问题，特别是在只有一个源域可用的情况下。我们提出了一种有效的方法，包括两个关键步骤：源域的多样化和基于类预测置信度和局部化的检测对齐。

# 开放世界/词汇检测
## 用于开放式词汇目标检测的内置检测器中区域词对齐的探索
开放式词汇目标检测旨在检测独立于训练过程中使用的基本类别的新类别。大多数现代方法都坚持从大规模多模态语料库中学习视觉语言空间，然后将所获得的知识转移到现成的检测器，如 Faster RCNN。然而，在知识转移过程中，由于领域差距阻碍了对新类别的泛化能力，信息可能会衰减或破坏。为了缓解这一困境，我们在本文中提出了一个新的框架，名为 BIND，代表 Bulit in 检测器，以消除对模块更换或知识转移到现成检测器的需求。
## SHiNee：开放词汇对象检测的语义层次结构 Nexus
开放词汇表对象检测(OVOD)将检测转变为一种语言制导的任务，允许用户在推理过程中自由定义他们感兴趣的类词汇。然而，我们的初步调查表明，现有的Ovod 检测器在处理跨不同语义粒度的词汇表时表现出显着的可变性，这给现实世界的部署带来了担忧。为此，我们引入了语义层次 Nexus(SISH)，这是一种使用来自类层次的语义知识的新型分类器。

## 生成增强的负值以训练基于数据的目标检测器
用辨别性目标函数训练这种模型已被证明是成功的，但需要良好的正样本和负样本。然而，自由形式的性质和对象描述的开放词汇使得否定的空间非常大。以前的工作是随机抽样底片或使用基于规则的技术来构建底片。相反，我们建议利用现代生成模型中内置的大量知识来自动构建与原始数据更相关的负片。

## DetCLIPv3：迈向多功能生成开放词汇对象检测
现有的开放词汇表对象检测器通常需要用户提供一组预定义的类别，这大大限制了他们的应用场景。在本文中，我们介绍了一种高性能的检测器，它不仅擅长于开放词汇表的对象检测，而且还擅长为被检测的对象生成分层标签。

## 探索开放世界目标检测中的正交性
开放世界目标检测的目标是识别不可见类别的物体，并在提供其注释后逐步识别它们。与仅限于预定义类别的传统范式不同，这种设置承诺了一种使用类不可知信息来估计客观性的连续且可概括的方法。然而，实现客观性和类信息之间的这种去相关性被证明是具有挑战性的。在没有明确考虑的情况下，现有的方法通常对未知对象的召回率较低，并且会将它们错误地分类到已知的类中。为了解决这个问题，我们在检测过程中利用了三个级别的正交性。

## 温度调节 Detection Transformer
提出了一种新的开放词汇检测框架。我们的框架使用图像级标签和详细的检测注释(如果可用)。我们的框架分三个步骤进行。


# 抓取检测
## 通过领域先验知识推广 6-DoF 抓取检测
本文重点研究了 6-DOF 抓取检测方法的泛化能力。虽然基于学习的抓取检测方法可以利用从训练集学习的抓取分布来预测不可见对象的抓取姿势，但当遇到形状和结构不同的对象时，它们的性能往往会显着下降。为了增强抓取检测方法的泛化能力，我们融合了机器人抓取的领域先验知识，使其能够更好地适应形状和结构差异较大的对象。
## 语言驱动的抓取检测
抓握检测是各种工业应用中一个持久而复杂的挑战。最近，已经提出了许多方法和数据集来解决抓取检测问题。然而，他们中的大多数人并不认为使用自然语言作为检测抓握姿势的条件。在本文中，我们介绍了一个新的语言驱动的抓取检测数据集“抓取任何东西++”，该数据集具有 3M 个对象上的 1M 个样本和超过 10M 的抓取指令。我们利用基础模型创建了一个具有相应图像和抓取提示的大规模场景语料库。我们将语言驱动的抓取检测任务视为一个条件生成问题。借鉴扩散模型在生成任务中的成功，并考虑到语言在这项任务中起着至关重要的作用，我们提出了一种新的基于扩散模型的语言驱动的抓取检测方法。

# 雷达目标检测
## RadSimReal：通过模拟弥补雷达目标检测中合成数据和真实数据之间的差距
利用神经网络对雷达图像中的目标进行检测，在提高自主驾驶方面显示出巨大的潜力。然而，从真实雷达图像中获取对训练这些网络至关重要的注释数据集是具有挑战性的，特别是在雷达性能优越的远程探测和不利天气和照明条件的情况下。为了应对这一挑战，我们提出了 RadSimReal，这是一种创新的物理雷达模拟，能够生成合成雷达图像，并附带各种雷达类型和环境条件的注释，所有这些都不需要实际的数据收集。
# 其他
## CAT：利用类间动力学进行域自适应目标检测
域自适应目标检测旨在使检测模型适应注释数据不可用的域。


## CrossKD：用于目标检测的十字头知识提取
知识提取（KD）已被证明是一种有效的学习紧凑目标检测器的模型压缩技术。现有的最先进的目标检测 KD 方法大多基于特征模仿。在本文中，我们提出了一种通用而有效的预测模拟蒸馏方案，称为 CrossKD。

## SDDGR：用于类增量目标检测的基于稳定扩散的深度生成重放
在类增量学习（CIL）领域，随着生成模型的不断改进，生成重放作为一种减轻灾难性遗忘的方法变得越来越突出。

## 面向可扩展的三维异常检测和定位：基于三维异常合成的基准和自监督学习网络
近年来，三维异常检测这一涉及细粒度几何判别的关键问题越来越受到关注。然而，缺乏丰富的真实三维异常数据限制了当前模型的可扩展性。
## Endow SAM with Keen Eyes：用于视频伪装目标检测的时空提示学习
分割一切模型（SAM）是一种即时驱动的基础模型，在自然图像分割中表现出了显著的性能。然而，它在视频伪装对象检测（VCOD）中的应用遇到了挑战，主要源于被忽视的时间-空间关联以及用户提供的难以用肉眼辨别的伪装对象提示
的不可靠性。为了解决上述问题，我们赋予 SAM 敏锐的洞察力，并提出了时空提示 SAM（TSP-SAM），这是一种通过巧妙的提示学习方案为 VCOD 量身定制的新方法。
## 双曲线异常检测
异常检测是工业场景中一项具有挑战性的计算机视觉任务。深度学习的进步不断革新基于视觉的异常检测方法，在监督和自监督异常检测方面都取得了长足的进展。常用的流水线是通过使用基于距离的损失函数约束特征嵌入来优化模型。然而，这些方法在欧氏空间中有效，并且不能很好地利用非欧氏空间中的数据。在本文中，我们首次探索了非欧氏空间的代表双曲空间中的异常检测任务，并提出了一种双曲
异常检测（ HypAD）方法。




## CLIP BEVFormer：利用Ground Truth流增强基于多视图图像的 BEV 检测器
自动驾驶是计算机视觉中塑造交通未来的一个关键领域。在这种范式中，系统的主干在解释复杂环境方面发挥着至关重要的作用。然而，一个值得注意的挑战是，在鸟瞰图元素方面缺乏明确的监督。为了解决这一限制，我们引入了 CLIP BEV，这是一种利用对比学习技术的力量来增强具有真实信息流的多视图图像衍生 BEV主干的新方法。

## 基于多粒度时空表示学习的多尺度视频异常检测
视频异常检测的最新进展表明，外观和运动特征在区分异常模式和正常模式方面起着至关重要的作用。然而，我们注意到，异常的空间尺度的影响被忽略了。许多异常事件发生在有限的局部区域和严重的背景噪声干扰了异常变化的学习。同时，大多数现有的方法都受到粗粒度建模方法的限制，这些方法不足以学习高度判别特征来区分小规模异常和正常模式之间的细微差异。为此，本文通过多粒度时空表示学习来解决多尺度视频异常检测问题。

## 弱监督视频异常检测的规范性引导文本提示
弱监督视频异常检测（WSVAD）是一项具有挑战性的任务。基于弱标签生成细粒度伪标签，然后对分类器进行自训练是目前一种很有前途的解决方案。然而，由于现有方法仅使用 RGB 视觉模态，并且忽略了类别文本信息的利用，从而限制了更准确的伪标签的生成，并影响了自训练的性能。受本文基于事件描述的手动标记过程的启发，我们提出了一种新的基于文本提示和规范性引导的 WSVAD 伪标记生成和自训练框架。我们的想法是转移对比语言图像预训练（CLIP）模型的丰富的语言视觉知识，用于对齐视频事件描述文本和相应的视频帧，以生成伪标签。

## 用于开放世界检测的具有合成字幕的双曲线学习
开放世界检测带来了重大挑战，因为它需要使用目标类别标签或自由格式文本来检测任何对象。现有的相关工作通常使用大规模的手动注释字幕数据集进行训练，这些数据集的收集成本极高。相反，我们建议从视觉语言模型（VLM）中转移知识，以自动丰富开放词汇描述。

## 复杂工业图像的监督异常检测
工业生产线上的自动化目视检查对于提高各个行业的产品质量至关重要。异常检测（AD）方法是实现这一目的的强大工具。然而，现有的公共数据集主要由没有异常的图像组成，这限制了 AD 方法在生产环境中的实际应用。为了应对这一挑战，我们提出了Valeo 异常数据集（VAD），这是一个新颖的真实世界工业数据集，包括 5000 张图像，包括 20 多个子类中 2000 个具有挑战性的真实缺陷实例。

## 改进激光雷达视觉基础模型提取的三大支柱
自监督图像主干可以用于非常有效地处理复杂的 2D 任务（例如语义分割对象发现），并且很少或没有下游监督。理想情况下，激光雷达的 3D 主干应该能够在提取这些强大的 2D 特征后继承这些特性。基于自动驾驶数据的图像到激光雷达的
最新提取方法显示出了良好的结果，这要归功于不断改进的提取方法。然而，当通过线性探测来测量提取特征与完全监督特征的质量时，我们仍然注意到巨大的性能差距。

## 用于多标签时间动作检测的双 DETR
时间动作检测（TAD）旨在识别未修剪视频中的动作边界和相应的类别。受DETR 在对象检测中的成功启发，几种方法将基于查询的框架应用于 TAD 任务。然而，这些方法主要遵循 DETR 来预测实例级别的动作（即通过其中心点来识别每个动作），从而导致次优边界定位。为了解决这个问题，我们提出了一种新的基于双层查询的 TAD 框架，即 DualDETR，用于从实例级和边界级检测动作。

## 时间动作检测模型对抗时间腐蚀的鲁棒性基准测试
时间动作检测（TAD）旨在定位长期未修剪视频中的动作位置和识别动作类别。尽管许多方法已经取得了有希望的结果，但它们的鲁棒性还没有得到彻底的研究。在实践中，我们观察到视频中的时间信息偶尔会被破坏，例如帧丢失或模糊。有趣的是，即使只有一帧受到影响，现有的方法也经常会导致性能显著下降。为了正式评估鲁棒性，我们建立了两个时间损坏鲁棒性基准，即 THUMOS14-C 和 ActivityNet-v1.3-C。在本文中，我们广泛分析了七种领先的 TAD 方法的鲁棒性，并获得了一些有趣的发现。









## 学习分布外检测的可转移负提示
现有的即时学习方法在分布外（OOD）检测中显示出一定的能力，但在其训练中目标数据集中缺乏 OOD 图像可能导致 OOD 图像和分布内（ID）类别之间的不匹配，从而导致高的假阳性率。为了解决这个问题，我们引入了一种新的 OOD检测方法，称为“NegPrompt”，以学习一组负提示，每个负提示表示给定类标签的负内涵，用于划定 ID 和 OOD 图像之间的边界。

## 在不断变化的测试领域中，对象检测器应该如何以及何时更新？
众所周知，当深度学习模型在测试时遇到分布变化时，其性能会恶化。已经提出了测试时间自适应（TTA）算法来在线调整模型，同时推断测试数据。然而，现有的研究主要集中在通过优化批处理规范化层或分类头的分类任务上，但这种方法限制了其对各种模型架构（如 Transformers）的适用性，并使其难以应用于其他任务（如对象检测）。在本文中，我们提出了一种新的在线自适应方法，用于在不断变化的测试域中进行对象检测，考虑到要更新模型的哪一部分、如何更新以及何时执行更新。

## CosalPure：从组图像中学习概念用于鲁棒共显著性检测
共同显著对象检测（CoSOD）旨在识别给定图像组中的共同和显著（通常在前景中）区域。尽管取得了重大进展，但最先进的 CoSOD 很容易受到一些对抗性扰动的影响，导致精度大幅下降。对抗性扰动可以误导 CoSOD，但不会改变共同显著对象的高级语义信息（例如概念）。在本文中，我们提出了一种新的鲁棒性增强框架，首先基于输入组图学习共同显著对象的概念，然后利用这一概念来纯化对抗性扰动，这些扰动随后被馈送到 CoSOD 以进行鲁棒性增强。



## GLOW：针对目标检测的全局布局感知攻击
敌意攻击的目的是扰乱图像，使预测器输出错误的结果。由于结构化攻击的研究有限，对自然多目标场景进行一致性检查是对抗传统对手攻击的一种实用方法。更多想要的攻击应该能够通过这样的一致性检查来愚弄防御。因此，我们提出了第一种方法 GLOW，它通过生成全局布局感知的对抗性攻击来应对各种攻击请求，其中明确地建立了分类布局约束和几何布局约束。


## FakeInVersion：学习通过倒置稳定扩散从看不见的文本到图像模型中检测图像
由于 GenAI 系统被滥用的可能性很高，检测合成图像的任务最近引起了研究界的极大兴趣。不幸的是，随着新的高保真文本到图像模型以令人眼花缭乱的速度发展，现有的图像空间探测器很快就被淘汰了。在这项工作中，我们提出了一种新的合成图像检测器，它使用了通过对开源的预先训练的稳定扩散模型进行倒置而获得的特征。

## 在 Deepfake 检测中保持公平性概括
尽管近年来开发了有效的 Deepfake 检测模型，但最近的研究表明，这些模型会导致种族和性别等人口群体之间不公平的表现差异。这可能导致特定群体面临不公平的目标或被排除在检测之外，可能允许错误分类的深度假货操纵公众舆论，破坏对该模型的信任。解决这一问题的现有方法是提供公平损失函数。该算法对域内评估具有较好的公平性，但对跨域测试不能保持公平性。这凸显了公平泛化在打击深度
假货中的重要意义。在这项工作中，我们提出了一种方法，通过同时考虑特征损失和优化方面来解决 Deepfake 检测中的公平性泛化问题。
## 通过潜在空间增强超越伪造特定性，实现可推广的 Deepfake 检测
当训练数据和测试数据的分布不匹配时，深伪检测面临着严重的泛化障碍，性能下降。一种被广泛接受的解释是，这些探测器倾向于过度适应特定于伪造物的东西，而不是学习广泛适用于各种伪造物的特征。为了解决这个问题，我们提出了一个简单但有效的检测器，称为 LSDA，它基于一个启发式的思想：具有更广泛种类的伪造的表示应该能够学习更通用的决策边界，从而减少方法特定特征的过度匹配。基于这一思想，我们提出了通过构造和模拟潜在空间中伪造特征内部和之间的变化来扩大伪造空间。
## 用于对象检测的主动域自适应误报预测
域适应使模型适应不同的场景，具有不同的外观。在该领域中，主动域自适应对于有效地采样目标域中的有限数量的数据至关重要。我们提出了一种主动域自适应目标检测方法，重点是对目标的不可检测性进行量化。现有的主动采样方法在估计模型预测的不确定性时遇到了考虑未检测对象的挑战。我们提出的主动抽样策略使用主动学习方法来解决这个问题，该方法同时考虑了不确定性和不可检测性。
## InstaGen：通过合成数据集训练增强对象检测
在本文中，我们提出了一种新的范例来增强目标检测器的能力，例如通过对扩散模型生成的合成数据集进行训练来扩展类别或提高检测性能。具体地说，我们将实例级定位头部集成到预先训练的生成性扩散模型中，以增强其在生成图像中定位实例的能力。使用来自现成对象检测器的监督和对未被检测器覆盖的(新的)类别的新颖的自我训练方案，训练定位头部以使类别名称的文本嵌入与扩散模型的区域视觉特征对齐。
## 重新思考有向目标检测的边界不连续性问题
有向目标检测在过去的几年中得到了迅速的发展，其中旋转等差对于检测器预测旋转的盒子是至关重要的。当物体旋转时，预计预测能够保持相应的旋转，但当物体在边界角度附近旋转时，有时会观察到角度预测的严重突变，这是众所周知的边界不连续问题。长期以来，这个问题一直被认为是由于角边界处损失的急剧增加造成的，广泛使用的联合 OpTim IOU 类方法通过损失平滑来处理这个问题。然而，我们实验发现，即使是最先进的类似借条的方法实际上也无法解决问题。进一步分析发现，求解的关键在于平滑函数的编码方式，而不是联合优化或独立优化。在现有的 IOU 类方法中，该模型本质上是试图拟合盒子和物体之间的角度关系，其中角边界处的断点使得预测非常不稳定。

## 突出性 DETR：通过分层突出性过滤细化增强 Detection Transformer
类 DETR 方法以端到端的方式显著提高了检测性能。它们的主流两阶段框架执行密集的自我注意，并选择一小部分查询进行稀疏交叉注意，这被证明是有效的，但也引入了沉重的计算负担和对稳定查询选择的高度依赖。本文证明了在两阶段初始化中，次优的两阶段选择策略由于选择的查询和对象之间的不匹配而导致规模偏差和冗余。为了解决这些问题，我们提出了分层显著过滤精化算法，它只对过滤后的区分查询执行变换编码，以在计算效率和精度之间取得更好的折衷。
